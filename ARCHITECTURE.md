# MiniScript Compiler - Project Architecture & Overview

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MiniScript Compiler                       â”‚
â”‚                      (compiler.py)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚             â”‚             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Input        â”‚    â”‚    â”‚   Output        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ MiniScript    â”‚    â”‚    â”‚ Three-Address  â”‚
        â”‚ Source Code   â”‚    â”‚    â”‚ Code (TAC)     â”‚
        â”‚ (.ms files)   â”‚    â”‚    â”‚                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       COMPILER PHASES                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Phase 1: Lexical Analysis              â”‚
        â”‚  (lexer.py)                             â”‚
        â”‚  - Tokenization                         â”‚
        â”‚  - Error Detection                      â”‚
        â”‚  Output: Token Stream                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Phase 2: Syntax Analysis (Parsing)     â”‚
        â”‚  (parser.py)                            â”‚
        â”‚  - Recursive Descent LL(1)              â”‚
        â”‚  - Error Recovery                       â”‚
        â”‚  Output: Abstract Syntax Tree           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Phase 3: Semantic Analysis             â”‚
        â”‚  (semantic_analyzer.py)                 â”‚
        â”‚  - Symbol Table Management              â”‚
        â”‚  - Type Checking                        â”‚
        â”‚  - Scope Resolution                     â”‚
        â”‚  Output: Validated AST                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Phase 4: Intermediate Code Generation  â”‚
        â”‚  (tac_generator.py)                     â”‚
        â”‚  - TAC Emission                         â”‚
        â”‚  - Label/Temp Management                â”‚
        â”‚  Output: Three-Address Code             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Module Dependencies

```
compiler.py (Main Entry)
    â”‚
    â”œâ”€â–º lexer.py
    â”‚   â””â”€â–º token_types.py
    â”‚
    â”œâ”€â–º parser.py
    â”‚   â”œâ”€â–º token_types.py
    â”‚   â””â”€â–º ast_nodes.py
    â”‚
    â”œâ”€â–º semantic_analyzer.py
    â”‚   â”œâ”€â–º ast_nodes.py
    â”‚   â””â”€â–º symbol_table.py
    â”‚
    â””â”€â–º tac_generator.py
        â””â”€â–º ast_nodes.py
```

---

## ğŸ”„ Data Flow Through Compilation

```
     Source Code: "var x = 5 + 3;"
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LEXER (lexer.py)        â”‚
    â”‚ Tokenizes the code      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Token Stream:
    [VAR, ID(x), ASSIGN, INT(5), PLUS, INT(3), SEMICOLON, EOF]
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PARSER (parser.py)      â”‚
    â”‚ Builds syntax tree      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    AST (Abstract Syntax Tree):
    Program
    â””â”€â”€ VarDeclaration
        â”œâ”€â”€ name: "x"
        â””â”€â”€ initializer: BinaryOp
            â”œâ”€â”€ left: IntLiteral(5)
            â”œâ”€â”€ operator: "+"
            â””â”€â”€ right: IntLiteral(3)
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ SEMANTIC ANALYZER        â”‚
    â”‚ (semantic_analyzer.py)   â”‚
    â”‚ - Type checks            â”‚
    â”‚ - Symbol management      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Validated AST + Symbol Table + Type Info
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ TAC GENERATOR            â”‚
    â”‚ (tac_generator.py)       â”‚
    â”‚ - Generates IR           â”‚
    â”‚ - Manages temporaries    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Three-Address Code:
     0: x = ASSIGN 5
     1: t1 = 5 + 3
     2: x = ASSIGN t1
```

---

## ğŸ¯ Compiler Phases Detail

### Phase 1: Lexical Analysis (Lexer)

**Input:** Raw source code string

**Process:**
```python
Lexer scans character by character:
- Recognizes patterns (keywords, identifiers, etc.)
- Groups characters into tokens
- Skips whitespace and comments
- Tracks line/column for errors
```

**Output:** Token stream with type information

**Key Functions:**
- `tokenize()` - Main entry point
- `current_char()` - Peek at current character
- `advance()` - Move to next character
- `read_string()` - Handle string literals
- `read_number()` - Handle numeric literals
- `read_identifier()` - Handle identifiers/keywords

---

### Phase 2: Parsing (Parser)

**Input:** Token stream

**Process:**
```python
Parser uses recursive descent:
- Each grammar rule â†’ parsing function
- Lookahead for decisions
- Build tree recursively
- Error recovery on syntax errors
```

**Output:** Abstract Syntax Tree

**Key Methods:**
- `parse()` - Top-level entry
- `statement()` - Parse any statement
- `expression()` - Parse expressions
- `primary()` - Parse literals/identifiers
- Error recovery: `synchronize()`

---

### Phase 3: Semantic Analysis

**Input:** Abstract Syntax Tree

**Process:**
```python
Visitor pattern traversal:
- Build symbol table
- Check for undeclared variables
- Verify type compatibility
- Validate control structure conditions
- Manage nested scopes
```

**Output:** Type information + validation results

**Key Components:**
- `SymbolTable` - Symbol management
- `TypeChecker` - Type inference
- Visitor methods for each AST node type

---

### Phase 4: TAC Generation

**Input:** Validated Abstract Syntax Tree

**Process:**
```python
Tree traversal generates IR:
- Emit instructions for each operation
- Generate temporary variables
- Create labels for control flow
- Maintain instruction sequence
```

**Output:** Three-Address Code listing

**Key Concepts:**
- Temporaries: `t1, t2, t3, ...`
- Labels: `L1, L2, L3, ...`
- Instructions: Assignment, binary op, jumps, etc.

---

## ğŸ“Š Language Grammar Hierarchy

```
Expression Grammar (Lowest to Highest Precedence):

Level 1: LogicalOr (||)
    â†“
Level 2: LogicalAnd (&&)
    â†“
Level 3: Equality (==, !=)
    â†“
Level 4: Relational (<, >, <=, >=)
    â†“
Level 5: Additive (+, -)
    â†“
Level 6: Multiplicative (*, /, %)
    â†“
Level 7: Unary (!, -)
    â†“
Level 8: Primary (literals, identifiers)

Example: 2 + 3 * 4

Parse Tree (shows precedence):
           Additive
          /    |    \
       Mult   +    Mult
        |            / \
        2           /   \
                  Mult   Mult
                   |      |
                   3      4

Result: 2 + (3 * 4) = 14
```

---

## ğŸ” Type System

```
Type Hierarchy:

Primitive Types:
â”œâ”€ int
â”‚  â””â”€ Can convert to: float
â”œâ”€ float
â”‚  â”œâ”€ Can convert to: (no implicit conversion)
â”‚  â””â”€ From: int (implicit)
â”œâ”€ bool
â”‚  â””â”€ Result of: comparisons, logical ops
â””â”€ string
   â””â”€ Literal only

Type Checking Rules:
â”œâ”€ Arithmetic ops: both must be numeric (int or float)
â”œâ”€ Comparison ops: return bool
â”œâ”€ Logical ops: conditions must be bool
â””â”€ Assignment: LHS and RHS types must be compatible

Type Inference:
â”œâ”€ Variable types inferred from initializers
â”œâ”€ Expression types from operand types
â””â”€ Default: 'auto' for uninitialized variables
```

---

## ğŸ¨ AST Node Types

```
ASTNode (Base)
â”œâ”€ Program
â”œâ”€ Statement
â”‚  â”œâ”€ VarDeclaration
â”‚  â”œâ”€ Assignment
â”‚  â”œâ”€ IfStatement
â”‚  â”œâ”€ WhileStatement
â”‚  â”œâ”€ ForStatement
â”‚  â”œâ”€ FunctionDeclaration
â”‚  â”œâ”€ ReturnStatement
â”‚  â””â”€ PrintStatement
â””â”€ Expression
   â”œâ”€ BinaryOp
   â”œâ”€ UnaryOp
   â”œâ”€ Identifier
   â”œâ”€ IntLiteral
   â”œâ”€ FloatLiteral
   â”œâ”€ StringLiteral
   â”œâ”€ BoolLiteral
   â”œâ”€ FunctionCall
   â””â”€ ArrayAccess

Note: All nodes include line/column for error reporting
```

---

## ğŸ’¾ Symbol Table Structure

```
Symbol Table:
â”œâ”€ Global Scope (Level 0)
â”‚  â”œâ”€ Variable: x (type: int)
â”‚  â”œâ”€ Variable: y (type: float)
â”‚  â””â”€ Function: add (params: [a, b])
â”‚
â””â”€ Function 'add' Scope (Level 1)
   â”œâ”€ Parameter: a (type: auto)
   â”œâ”€ Parameter: b (type: auto)
   â””â”€ Variable: result (type: auto)

Scope Resolution:
- When looking up a symbol, search from current scope upward
- Use closest matching symbol
- Error if not found at any level
```

---

## ğŸ”€ Control Flow in TAC

### If-Else Statement
```
Generated TAC:
LABEL entry_point
  (evaluate condition into t1)
  IF_FALSE t1 else_label
  (then body statements)
  GOTO end_label
LABEL else_label
  (else body statements)
LABEL end_label
  (continue)
```

### While Loop
```
Generated TAC:
LABEL loop_start
  (evaluate condition into t1)
  IF_FALSE t1 loop_end
  (body statements)
  GOTO loop_start
LABEL loop_end
  (continue)
```

### For Loop
```
Generated TAC:
  (init statements)
LABEL loop_start
  (evaluate condition into t1)
  IF_FALSE t1 loop_end
  (body statements)
  (update statements)
  GOTO loop_start
LABEL loop_end
  (continue)
```

---

## ğŸ“ˆ Compiler Performance

```
Input: Source Code of length n

Phase 1: Lexical Analysis
  Time: O(n)
  Space: O(n) for token list

Phase 2: Parsing
  Time: O(n) where n = token count
  Space: O(h) where h = AST height

Phase 3: Semantic Analysis
  Time: O(n) where n = AST nodes
  Space: O(s) where s = symbol table size

Phase 4: TAC Generation
  Time: O(n) where n = AST nodes
  Space: O(n) for TAC instructions

Total:
  Time Complexity: O(n)
  Space Complexity: O(n)

Where n = source code length
```

---

## ğŸ§ª Testing Coverage

```
Test Categories:

1. Lexical Analysis Tests
   âœ“ Token recognition
   âœ“ String handling
   âœ“ Number parsing
   âœ“ Comment handling
   âœ“ Error detection

2. Parser Tests
   âœ“ Variable declarations
   âœ“ Assignments
   âœ“ Control structures
   âœ“ Expressions
   âœ“ Operator precedence
   âœ“ Error recovery

3. Semantic Tests
   âœ“ Symbol table operations
   âœ“ Type checking
   âœ“ Scope resolution
   âœ“ Error detection

4. TAC Generation Tests
   âœ“ Simple expressions
   âœ“ Complex expressions
   âœ“ Control flow
   âœ“ Function calls
   âœ“ Temporary management
```

---

## ğŸ“Š Code Statistics

```
Codebase Metrics:

Source Code:
- Total Python files: 7
- Total lines of code: ~2,000
- Modules: 7
- Classes: 20+
- Functions/Methods: 80+

Documentation:
- Total markdown files: 7
- Total documentation pages: 70+
- Code comments: Comprehensive
- Example programs: 8

Tests:
- Test functions: 15+
- Test cases: 20+
- Coverage: Comprehensive

Examples:
- Sample programs: 8
- Lines of MiniScript: 50+
- Different features: All covered
```

---

## ğŸ“ Educational Components

```
What This Project Teaches:

Theory:
âœ“ Lexical analysis principles
âœ“ Context-free grammars
âœ“ Parsing techniques
âœ“ Semantic analysis
âœ“ Intermediate code generation
âœ“ Compiler design patterns

Practice:
âœ“ Modular code organization
âœ“ Error handling strategies
âœ“ Testing methodologies
âœ“ Documentation best practices
âœ“ Code quality principles
âœ“ Professional software engineering

Implementation:
âœ“ Token recognition
âœ“ Recursive descent parsing
âœ“ Symbol table management
âœ“ Type checking systems
âœ“ AST manipulation
âœ“ Code generation
```

---

## ğŸš€ Quick Reference

**To compile:** `python compiler.py <file.ms>`

**To test:** `python tests/test_compiler.py`

**To learn:** Start with QUICKSTART.md

**For examples:** Check `examples/` folder

**For theory:** Read GRAMMAR_ANALYSIS.md

**For complete details:** See PROJECT_REPORT.md

---

## âœ… Project Features

âœ“ **Complete** - All compiler phases
âœ“ **Documented** - 70+ pages
âœ“ **Tested** - Comprehensive test suite
âœ“ **Practical** - 8 working examples
âœ“ **Educational** - Perfect for learning
âœ“ **Professional** - Production quality
âœ“ **Clean** - Well-organized code
âœ“ **No Dependencies** - Pure Python

---

**Status:** âœ… Complete and Production-Ready

**For more information, see: DOCUMENTATION_INDEX.md**
